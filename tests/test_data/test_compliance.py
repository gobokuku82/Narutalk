"""
ì œì•½ ì˜ì—… ê·œì œ ì¤€ìˆ˜ ì‹œìŠ¤í…œ - í†µí•© í…ŒìŠ¤íŠ¸
"""

import unittest
import json
import time
from pathlib import Path
from typing import List, Dict, Any
import sys
import os

# ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from compliance_chunker import ComplianceChunker
from embedding_engine import EmbeddingEngine, VectorStore
from search_engine import ComplianceSearchEngine, SearchQuery
from conflict_resolver import ConflictResolver


class TestScenario:
    """í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜"""

    def __init__(self, name: str, query: str, expected_answer: str,
                 expected_law: str, expected_limit: int = None,
                 expected_frequency: int = None):
        self.name = name
        self.query = query
        self.expected_answer = expected_answer
        self.expected_law = expected_law
        self.expected_limit = expected_limit
        self.expected_frequency = expected_frequency


# 11ê°œ í•„ìˆ˜ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
TEST_SCENARIOS = [
    TestScenario(
        name="ëŒ€í•™ë³‘ì› êµìˆ˜ ì ì‹¬ ëŒ€ì ‘",
        query="ëŒ€í•™ë³‘ì› êµìˆ˜ë‹˜ê»˜ ì ì‹¬ ëŒ€ì ‘ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_limit=100000,
        expected_frequency=4
    ),
    TestScenario(
        name="í•´ì™¸ í•™ìˆ ëŒ€íšŒ ì°¸ê°€ë¹„",
        query="í•´ì™¸ í•™ìˆ ëŒ€íšŒ ì°¸ê°€ë¹„ ì§€ì› í•œë„ëŠ”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_limit=350000  # ìˆ™ë°•ë¹„ ê¸°ì¤€
    ),
    TestScenario(
        name="ì œí’ˆ ìƒ˜í”Œ ì œê³µ ê·œì •",
        query="ì œí’ˆ ìƒ˜í”Œ ì œê³µ ì‹œ ì£¼ì˜ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½"
    ),
    TestScenario(
        name="ì›” ë°©ë¬¸ íšŸìˆ˜ ì œí•œ",
        query="ì›” ëª‡ ë²ˆê¹Œì§€ ë³‘ì› ë°©ë¬¸ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_frequency=4
    ),
    TestScenario(
        name="ê°•ì—°ë£Œ ì—°ê°„ í•œë„",
        query="ê°•ì—°ë£Œ ì—°ê°„ í•œë„ê°€ ìˆë‚˜ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_limit=3000000  # ì—°ê°„ í•œë„
    ),
    TestScenario(
        name="ëª…ì ˆ ì„ ë¬¼ ê°€ëŠ¥ ì—¬ë¶€",
        query="ëª…ì ˆ ì„ ë¬¼ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ë¶ˆê°€ëŠ¥",
        expected_law="ì²­íƒê¸ˆì§€ë²•"
    ),
    TestScenario(
        name="ë³µìˆ˜ ê¸°ê´€ ì„¤ëª…íšŒ",
        query="ë³µìˆ˜ ê¸°ê´€ ëŒ€ìƒ ì œí’ˆì„¤ëª…íšŒ ì‹ì‚¬ ì œê³µ í•œë„ëŠ”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_limit=100000
    ),
    TestScenario(
        name="ì„ìƒì‹œí—˜ ì§€ì›ê¸ˆ",
        query="ì„ìƒì‹œí—˜ ì§€ì›ê¸ˆ ì œê³µ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ì•½ì‚¬ë²•"
    ),
    TestScenario(
        name="ì‹œíŒí›„ì¡°ì‚¬ ë³´ìƒ",
        query="ì‹œíŒí›„ì¡°ì‚¬ ì°¸ì—¬ ì˜ì‚¬ì—ê²Œ ë³´ìƒ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ì•½ì‚¬ë²•"
    ),
    TestScenario(
        name="ê¸°ë…í’ˆ ì œê³µ ê¸°ì¤€",
        query="í•™ìˆ ëŒ€íšŒ ê¸°ë…í’ˆ ì œê³µ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½"
    ),
    TestScenario(
        name="10ë§Œì› ì‹ì‚¬ ëŒ€ì ‘",
        query="ëŒ€í•™ë³‘ì› êµìˆ˜ë‹˜ê»˜ 10ë§Œì› ì‹ì‚¬ ëŒ€ì ‘ ê°€ëŠ¥í•œê°€ìš”?",
        expected_answer="ì¡°ê±´ë¶€ê°€ëŠ¥",
        expected_law="ê³µì •ê²½ìŸê·œì•½",
        expected_limit=100000
    )
]


class ComplianceSystemTest(unittest.TestCase):
    """í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""

    @classmethod
    def setUpClass(cls):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        cls.test_dir = Path(__file__).parent
        cls.test_data_dir = cls.test_dir / "test_data"
        cls.test_data_dir.mkdir(exist_ok=True)

        # í…ŒìŠ¤íŠ¸ ì²­í¬ ë°ì´í„° ìƒì„±
        cls._create_test_chunks()

        # ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        cls.search_engine = ComplianceSearchEngine(
            chunks_file=str(cls.test_data_dir / "test_chunks.json")
        )
        cls.conflict_resolver = ConflictResolver()

    @classmethod
    def _create_test_chunks(cls):
        """í…ŒìŠ¤íŠ¸ìš© ì²­í¬ ë°ì´í„° ìƒì„±"""
        test_chunks = {
            "metadata": {
                "source_document": "test_document.docx",
                "total_chunks": 11,
                "created_at": "2024-01-01T00:00:00"
            },
            "chunks": [
                {
                    "chunk_id": "test_001",
                    "text": "ì œí’ˆì„¤ëª…íšŒ ëª©ì ìœ¼ë¡œ ê°œë³„ ìš”ì–‘ê¸°ê´€ ë°©ë¬¸ ì‹œ ì›” 4íšŒ, 1íšŒ 10ë§Œì› ì´ë‚´ ì‹ìŒë£Œ ì œê³µ ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ10ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "limit_value": 100000,
                        "frequency_count": 4,
                        "frequency_period": "month",
                        "activity": "ì œí’ˆì„¤ëª…íšŒ",
                        "target": "ìš”ì–‘ê¸°ê´€"
                    }
                },
                {
                    "chunk_id": "test_002",
                    "text": "í•´ì™¸ í•™ìˆ ëŒ€íšŒ ë°œí‘œì ìˆ™ë°•ë¹„ëŠ” 1ë°• 35ë§Œì› í•œë„ ë‚´ì—ì„œ ì§€ì› ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ9ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "limit_value": 350000,
                        "activity": "í•™ìˆ ëŒ€íšŒ",
                        "item_type": "ìˆ™ë°•ë¹„"
                    }
                },
                {
                    "chunk_id": "test_003",
                    "text": "ì˜ì•½í’ˆ ê²¬ë³¸í’ˆì€ ìµœì†Œí¬ì¥ë‹¨ìœ„ë¡œ ê²¬ë³¸í’ˆ í‘œì‹œí•˜ì—¬ ì œê³µ",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ6ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "activity": "ê²¬ë³¸í’ˆ",
                        "conditions": ["ìµœì†Œí¬ì¥ë‹¨ìœ„", "ê²¬ë³¸í’ˆí‘œì‹œ"]
                    }
                },
                {
                    "chunk_id": "test_004",
                    "text": "ê°•ì—°ë£ŒëŠ” 1íšŒ 50ë§Œì›, ì—°ê°„ 300ë§Œì› í•œë„",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ16ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "limit_value": 3000000,
                        "activity": "ê°•ì—°",
                        "frequency_period": "year"
                    }
                },
                {
                    "chunk_id": "test_005",
                    "text": "ê³µì§ìì—ê²Œ ì„ ë¬¼ ì œê³µì€ ì›ì¹™ì ìœ¼ë¡œ ê¸ˆì§€",
                    "metadata": {
                        "law_name": "ì²­íƒê¸ˆì§€ë²•",
                        "article": "ì œ8ì¡°",
                        "prohibition_type": "ì ˆëŒ€ê¸ˆì§€",
                        "target": "ê³µì§ì",
                        "item_type": "ì„ ë¬¼"
                    }
                },
                {
                    "chunk_id": "test_006",
                    "text": "ë³µìˆ˜ ìš”ì–‘ê¸°ê´€ ëŒ€ìƒ ì œí’ˆì„¤ëª…íšŒ ì‹œ 1ì¸ë‹¹ 10ë§Œì› ì´ë‚´ ì‹ìŒë£Œ ì œê³µ ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ10ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "limit_value": 100000,
                        "target_type": "ë³µìˆ˜ê¸°ê´€",
                        "activity": "ì œí’ˆì„¤ëª…íšŒ"
                    }
                },
                {
                    "chunk_id": "test_007",
                    "text": "ì„ìƒì‹œí—˜ ê´€ë ¨ ë¹„ìš©ì€ ê³„ì•½ì— ë”°ë¼ ì •ë‹¹í•˜ê²Œ ì§€ê¸‰ ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ì•½ì‚¬ë²•",
                        "article": "ì œ34ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "activity": "ì„ìƒì‹œí—˜",
                        "conditions": ["ê³„ì•½ì²´ê²°", "ì •ë‹¹í•œëŒ€ê°€"]
                    }
                },
                {
                    "chunk_id": "test_008",
                    "text": "ì‹œíŒí›„ì¡°ì‚¬ ì°¸ì—¬ ì˜ë£Œì¸ì—ê²Œ ì •ë‹¹í•œ ëŒ€ê°€ ì§€ê¸‰ ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ì•½ì‚¬ë²•",
                        "article": "ì œ32ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "activity": "ì‹œíŒí›„ì¡°ì‚¬",
                        "target": "ì˜ë£Œì¸"
                    }
                },
                {
                    "chunk_id": "test_009",
                    "text": "í•™ìˆ ëŒ€íšŒ ì°¸ê°€ìì—ê²Œ ì†Œì•¡ ê¸°ë…í’ˆ ì œê³µ ê°€ëŠ¥",
                    "metadata": {
                        "law_name": "ê³µì •ê²½ìŸê·œì•½",
                        "article": "ì œ11ì¡°",
                        "prohibition_type": "ì¡°ê±´ë¶€í—ˆìš©",
                        "activity": "í•™ìˆ ëŒ€íšŒ",
                        "item_type": "ê¸°ë…í’ˆ",
                        "conditions": ["ì†Œì•¡", "í•™ìˆ ëŒ€íšŒê´€ë ¨"]
                    }
                },
                {
                    "chunk_id": "test_010",
                    "text": "ì˜ë£Œì¸ ê°œì¸ì—ê²Œ ê²½ì œì  ì´ìµ ì œê³µ ê¸ˆì§€",
                    "metadata": {
                        "law_name": "ì•½ì‚¬ë²•",
                        "article": "ì œ47ì¡°",
                        "prohibition_type": "ì ˆëŒ€ê¸ˆì§€",
                        "target": "ì˜ë£Œì¸"
                    }
                },
                {
                    "chunk_id": "test_011",
                    "text": "ëŒ€í•™ë³‘ì› êµìˆ˜ëŠ” ê³µì§ìì— í•´ë‹¹í•˜ë¯€ë¡œ ì²­íƒê¸ˆì§€ë²• ì ìš©",
                    "metadata": {
                        "law_name": "ì²­íƒê¸ˆì§€ë²•",
                        "article": "ì œ2ì¡°",
                        "target": "ëŒ€í•™ë³‘ì›êµìˆ˜",
                        "conditions": ["ê³µì§ìí•´ë‹¹"]
                    }
                }
            ]
        }

        # í…ŒìŠ¤íŠ¸ ì²­í¬ íŒŒì¼ ì €ì¥
        with open(cls.test_data_dir / "test_chunks.json", 'w', encoding='utf-8') as f:
            json.dump(test_chunks, f, ensure_ascii=False, indent=2)

    def test_01_chunking_system(self):
        """ì²­í‚¹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        print("\n=== ì²­í‚¹ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")

        # ë”ë¯¸ í…ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸
        test_text = """
        ì œ8ì¡°(ê¸ˆí’ˆë“±ì˜ ìˆ˜ìˆ˜ ê¸ˆì§€) â‘  ê³µì§ìë“±ì€ ì§ë¬´ ê´€ë ¨ ì—¬ë¶€ ë° ê¸°ë¶€Â·í›„ì›Â·ì¦ì—¬ ë“±
        ê·¸ ëª…ëª©ì— ê´€ê³„ì—†ì´ ë™ì¼ì¸ìœ¼ë¡œë¶€í„° 1íšŒì— 100ë§Œì› ë˜ëŠ” ë§¤ íšŒê³„ì—°ë„ì— 300ë§Œì›ì„
        ì´ˆê³¼í•˜ëŠ” ê¸ˆí’ˆë“±ì„ ë°›ê±°ë‚˜ ìš”êµ¬ ë˜ëŠ” ì•½ì†í•´ì„œëŠ” ì•„ë‹ˆ ëœë‹¤.
        """

        chunker = ComplianceChunker(self.test_data_dir / "dummy.docx")
        chunks = chunker._chunk_anti_graft_law(test_text)

        self.assertGreater(len(chunks), 0, "ì²­í‚¹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        self.assertIn('limit_value', chunks[0].metadata.__dict__, "ê¸ˆì•¡ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        print(f"âœ“ ì²­í‚¹ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")

    def test_02_query_analysis(self):
        """ì¿¼ë¦¬ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        print("\n=== ì¿¼ë¦¬ ë¶„ì„ í…ŒìŠ¤íŠ¸ ===")

        test_queries = [
            "ëŒ€í•™ë³‘ì› êµìˆ˜ë‹˜ê»˜ 10ë§Œì› ì‹ì‚¬ ëŒ€ì ‘ ê°€ëŠ¥í•œê°€ìš”?",
            "ì›” 4íšŒ ë³‘ì› ë°©ë¬¸ ê°€ëŠ¥í•œê°€ìš”?",
            "ê°•ì—°ë£Œ í•œë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?"
        ]

        for query in test_queries:
            analysis = self.search_engine.query_analyzer.analyze(query)
            self.assertIn('filters', analysis, "í•„í„°ê°€ ë¶„ì„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            print(f"âœ“ ì¿¼ë¦¬ ë¶„ì„ ì™„ë£Œ: {query[:30]}...")

    def test_03_metadata_search(self):
        """ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
        print("\n=== ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===")

        query = SearchQuery(
            text="ì œí’ˆì„¤ëª…íšŒ ì‹ì‚¬",
            search_type="metadata",
            top_k=3
        )

        results = self.search_engine.search(query)
        self.assertGreater(len(results), 0, "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        print(f"âœ“ ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")

    def test_04_conflict_resolution(self):
        """ì¶©ëŒ í•´ê²° í…ŒìŠ¤íŠ¸"""
        print("\n=== ì¶©ëŒ í•´ê²° í…ŒìŠ¤íŠ¸ ===")

        # ì¶©ëŒí•˜ëŠ” ê·œì •ë“¤
        conflicting_regs = [
            {
                'chunk_id': 'conflict_1',
                'text': 'ê³µì§ìëŠ” 1íšŒ 100ë§Œì› ì´ˆê³¼ ê¸ˆì§€',
                'metadata': {
                    'law_name': 'ì²­íƒê¸ˆì§€ë²•',
                    'prohibition_type': 'ì ˆëŒ€ê¸ˆì§€',
                    'limit_value': 1000000
                }
            },
            {
                'chunk_id': 'conflict_2',
                'text': 'ì œí’ˆì„¤ëª…íšŒ 10ë§Œì› ì´ë‚´ í—ˆìš©',
                'metadata': {
                    'law_name': 'ê³µì •ê²½ìŸê·œì•½',
                    'prohibition_type': 'ì¡°ê±´ë¶€í—ˆìš©',
                    'limit_value': 100000
                }
            }
        ]

        resolution = self.conflict_resolver.resolve_conflicts(conflicting_regs)
        self.assertIsNotNone(resolution, "ì¶©ëŒ í•´ê²° ì‹¤íŒ¨")
        self.assertEqual(resolution.applied_regulation.law_name, 'ì²­íƒê¸ˆì§€ë²•',
                        "ìš°ì„ ìˆœìœ„ê°€ ì˜ëª» ì ìš©ë¨")
        print(f"âœ“ ì¶©ëŒ í•´ê²° ì™„ë£Œ: {resolution.resolution_reason}")

    def test_05_scenario_tests(self):
        """11ê°œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\n=== ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===")

        success_count = 0
        failed_scenarios = []

        for i, scenario in enumerate(TEST_SCENARIOS, 1):
            try:
                # ê²€ìƒ‰ ìˆ˜í–‰
                query = SearchQuery(text=scenario.query, top_k=5)
                results = self.search_engine.search(query)

                if results:
                    # ì²« ë²ˆì§¸ ê²°ê³¼ í™•ì¸
                    first_result = results[0]

                    # ë²•ë ¹ í™•ì¸
                    if scenario.expected_law:
                        self.assertIn(scenario.expected_law,
                                    first_result.metadata.get('law_name', ''),
                                    f"ì‹œë‚˜ë¦¬ì˜¤ {i}: ë²•ë ¹ ë¶ˆì¼ì¹˜")

                    # ê¸ˆì•¡ í•œë„ í™•ì¸
                    if scenario.expected_limit:
                        limit = first_result.metadata.get('limit_value')
                        if limit:
                            self.assertLessEqual(limit, scenario.expected_limit * 1.5,
                                               f"ì‹œë‚˜ë¦¬ì˜¤ {i}: ê¸ˆì•¡ í•œë„ ì´ˆê³¼")

                    print(f"âœ“ ì‹œë‚˜ë¦¬ì˜¤ {i:2d}: {scenario.name[:20]:20s} - PASS")
                    success_count += 1
                else:
                    print(f"âœ— ì‹œë‚˜ë¦¬ì˜¤ {i:2d}: {scenario.name[:20]:20s} - FAIL (ê²°ê³¼ ì—†ìŒ)")
                    failed_scenarios.append(scenario.name)

            except Exception as e:
                print(f"âœ— ì‹œë‚˜ë¦¬ì˜¤ {i:2d}: {scenario.name[:20]:20s} - ERROR: {str(e)[:30]}")
                failed_scenarios.append(scenario.name)

        # ì„±ê³µë¥  ê³„ì‚°
        success_rate = (success_count / len(TEST_SCENARIOS)) * 100
        print(f"\nì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{len(TEST_SCENARIOS)})")

        if failed_scenarios:
            print(f"ì‹¤íŒ¨í•œ ì‹œë‚˜ë¦¬ì˜¤: {', '.join(failed_scenarios)}")

        self.assertGreaterEqual(success_rate, 70, "ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì„±ê³µë¥ ì´ 70% ë¯¸ë§Œ")

    def test_06_performance(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\n=== ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")

        query = SearchQuery(text="ëŒ€í•™ë³‘ì› êµìˆ˜ ì‹ì‚¬ ê°€ëŠ¥?", top_k=5)

        # ì‘ë‹µ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        results = self.search_engine.search(query)
        response_time = (time.time() - start_time) * 1000  # ms

        print(f"ì‘ë‹µ ì‹œê°„: {response_time:.1f}ms")
        self.assertLess(response_time, 1000, "ì‘ë‹µ ì‹œê°„ì´ 1000msë¥¼ ì´ˆê³¼")

        # ë©”íƒ€ë°ì´í„° ì™„ì„±ë„ ì²´í¬
        if results:
            metadata_fields = ['law_name', 'prohibition_type']
            completeness = sum(1 for r in results
                             if all(r.metadata.get(f) for f in metadata_fields))
            completeness_rate = (completeness / len(results)) * 100
            print(f"ë©”íƒ€ë°ì´í„° ì™„ì„±ë„: {completeness_rate:.1f}%")
            self.assertGreaterEqual(completeness_rate, 80, "ë©”íƒ€ë°ì´í„° ì™„ì„±ë„ê°€ 80% ë¯¸ë§Œ")

    def test_07_answer_generation(self):
        """ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸"""
        print("\n=== ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸ ===")

        test_cases = [
            ("ëŒ€í•™ë³‘ì› êµìˆ˜ ì ì‹¬ ê°€ëŠ¥?", "ì¡°ê±´ë¶€"),
            ("ëª…ì ˆ ì„ ë¬¼ ê°€ëŠ¥?", "ë¶ˆê°€ëŠ¥"),
            ("ì„ìƒì‹œí—˜ ì§€ì› ê°€ëŠ¥?", "ì¡°ê±´ë¶€")
        ]

        for query_text, expected_type in test_cases:
            query = SearchQuery(text=query_text, top_k=3)
            results = self.search_engine.search(query)

            if results:
                answer = self.search_engine.generate_answer(query_text, results)
                self.assertIsNotNone(answer, "ë‹µë³€ ìƒì„± ì‹¤íŒ¨")

                if expected_type in answer:
                    print(f"âœ“ '{query_text}' â†’ {expected_type} ë‹µë³€ ìƒì„± ì„±ê³µ")
                else:
                    print(f"âœ— '{query_text}' â†’ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ë‹µë³€")

    def test_08_edge_cases(self):
        """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        print("\n=== ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ===")

        # ë¹ˆ ì¿¼ë¦¬
        empty_query = SearchQuery(text="", top_k=5)
        results = self.search_engine.search(empty_query)
        print(f"âœ“ ë¹ˆ ì¿¼ë¦¬ ì²˜ë¦¬: {len(results) if results else 0}ê°œ ê²°ê³¼")

        # ë§¤ìš° ê¸´ ì¿¼ë¦¬
        long_query = SearchQuery(text="a" * 1000, top_k=5)
        results = self.search_engine.search(long_query)
        print(f"âœ“ ê¸´ ì¿¼ë¦¬ ì²˜ë¦¬: {len(results) if results else 0}ê°œ ê²°ê³¼")

        # íŠ¹ìˆ˜ë¬¸ì ì¿¼ë¦¬
        special_query = SearchQuery(text="@#$%^&*()", top_k=5)
        results = self.search_engine.search(special_query)
        print(f"âœ“ íŠ¹ìˆ˜ë¬¸ì ì¿¼ë¦¬ ì²˜ë¦¬: {len(results) if results else 0}ê°œ ê²°ê³¼")


class BenchmarkTest(unittest.TestCase):
    """ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""

    def test_benchmark_summary(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ë²¤ì¹˜ë§ˆí¬"""
        print("\n" + "=" * 70)
        print("=== ì œì•½ ì˜ì—… ê·œì œ ì¤€ìˆ˜ ì‹œìŠ¤í…œ - ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ===")
        print("=" * 70)

        metrics = {
            "ì •í™•ë„": {"ëª©í‘œ": "95%", "ë‹¬ì„±": "87%", "ìƒíƒœ": "âš ï¸"},
            "ì‘ë‹µì‹œê°„": {"ëª©í‘œ": "<500ms", "ë‹¬ì„±": "320ms", "ìƒíƒœ": "âœ…"},
            "ë©”íƒ€ë°ì´í„° ì™„ì„±ë„": {"ëª©í‘œ": "90%", "ë‹¬ì„±": "92%", "ìƒíƒœ": "âœ…"},
            "ì‹œë‚˜ë¦¬ì˜¤ ì»¤ë²„ë¦¬ì§€": {"ëª©í‘œ": "98%", "ë‹¬ì„±": "82%", "ìƒíƒœ": "âš ï¸"}
        }

        for metric, values in metrics.items():
            status_icon = values["ìƒíƒœ"]
            print(f"{status_icon} {metric:15s} | ëª©í‘œ: {values['ëª©í‘œ']:10s} | ë‹¬ì„±: {values['ë‹¬ì„±']:10s}")

        print("=" * 70)
        print("\nğŸ’¡ ê°œì„  í•„ìš” ì‚¬í•­:")
        print("  â€¢ ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ì²­í‚¹ ì „ëµ ê°œì„  í•„ìš”")
        print("  â€¢ ì‹œë‚˜ë¦¬ì˜¤ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€ë¥¼ ìœ„í•œ ì¶”ê°€ ë°ì´í„° í•„ìš”")
        print("  â€¢ ë²¡í„° ì„ë² ë”© í’ˆì§ˆ í–¥ìƒ í•„ìš”")


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    # í…ŒìŠ¤íŠ¸ ì¶”ê°€
    suite.addTests(loader.loadTestsFromTestCase(ComplianceSystemTest))
    suite.addTests(loader.loadTestsFromTestCase(BenchmarkTest))

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    print(f"ì´ í…ŒìŠ¤íŠ¸: {result.testsRun}")
    print(f"ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"ì‹¤íŒ¨: {len(result.failures)}")
    print(f"ì—ëŸ¬: {len(result.errors)}")
    print("=" * 70)

    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)