# SupervisorAgent ì‹œìŠ¤í…œ ìƒì„¸ ì½”ë“œ ë¶„ì„ ë³´ê³ ì„œ

## ëª©ì°¨
1. [ì‹œìŠ¤í…œ ê°œìš”](#1-ì‹œìŠ¤í…œ-ê°œìš”)
2. [LangGraph í•µì‹¬ ê°œë…](#2-langgraph-í•µì‹¬-ê°œë…)
3. [State ê´€ë¦¬ ë©”ì»¤ë‹ˆì¦˜](#3-state-ê´€ë¦¬-ë©”ì»¤ë‹ˆì¦˜)
4. [ì½”ë“œ ì‹¤í–‰ íë¦„ (Line by Line)](#4-ì½”ë“œ-ì‹¤í–‰-íë¦„-line-by-line)
5. [LLM í˜¸ì¶œ ë¶„ì„](#5-llm-í˜¸ì¶œ-ë¶„ì„)
6. [í•¨ìˆ˜ë³„ ì…ì¶œë ¥ ëª…ì„¸](#6-í•¨ìˆ˜ë³„-ì…ì¶œë ¥-ëª…ì„¸)
7. [ë¯¸ì‚¬ìš© ì½”ë“œ ë¶„ì„](#7-ë¯¸ì‚¬ìš©-ì½”ë“œ-ë¶„ì„)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### ì•„í‚¤í…ì²˜ êµ¬ì¡°
```
FastAPI â†’ LangGraph StateGraph â†’ 5ê°œ ë…¸ë“œ ìˆœì°¨ ì‹¤í–‰ â†’ ì‘ë‹µ
         â†“
    AsyncSqliteSaver (ìƒíƒœ ì €ì¥)
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸
- **StateGraph**: LangGraphì˜ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„
- **AgentState**: ê°€ë³€ ìƒíƒœ (TypedDict)
- **AgentContext**: ë¶ˆë³€ ì„¤ì • (dataclass)
- **Runtime**: LangGraph ëŸ°íƒ€ì„ API

---

## 2. LangGraph í•µì‹¬ ê°œë…

### 2.1 StateGraph í´ë˜ìŠ¤
```python
from langgraph.graph import StateGraph, START, END

builder = StateGraph(
    state_schema=AgentState,    # TypedDict ìŠ¤í‚¤ë§ˆ
    context_schema=AgentContext  # Runtime Context ìŠ¤í‚¤ë§ˆ
)
```

**íŒŒë¼ë¯¸í„° ì„¤ëª…:**
- `state_schema`: ê·¸ë˜í”„ ì‹¤í–‰ ì¤‘ ë³€ê²½ë˜ëŠ” ìƒíƒœ ì •ì˜
- `context_schema`: ì‹¤í–‰ ì¤‘ ë¶ˆë³€ì¸ ì„¤ì • ì •ì˜

### 2.2 ë…¸ë“œ ì¶”ê°€ ë©”ì„œë“œ
```python
builder.add_node("node_name", callable_function)
```
- **"node_name"**: ë…¸ë“œ ì‹ë³„ì (ë¬¸ìì—´)
- **callable_function**: `(state, runtime) -> dict` ì‹œê·¸ë‹ˆì²˜ í•¨ìˆ˜
- **ë°˜í™˜ê°’**: State ì—…ë°ì´íŠ¸ ë”•ì…”ë„ˆë¦¬

### 2.3 ì—£ì§€ ì—°ê²° ë©”ì„œë“œ

#### ë‹¨ìˆœ ì—£ì§€
```python
builder.add_edge(START, "analyze_query")  # ì‹œì‘ â†’ ì²« ë…¸ë“œ
builder.add_edge("analyze_query", "create_plan")  # ë…¸ë“œ ê°„ ì—°ê²°
```

#### ì¡°ê±´ë¶€ ì—£ì§€
```python
builder.add_conditional_edges(
    "route_agents",              # ì†ŒìŠ¤ ë…¸ë“œ
    self.agent_executor.check_completion,  # ì¡°ê±´ í•¨ìˆ˜
    {
        "continue": "route_agents",     # ì¡°ê±´ê°’: íƒ€ê²Ÿë…¸ë“œ
        "aggregate": "aggregate_results",
        "error": "generate_response"
    }
)
```
- **ì¡°ê±´ í•¨ìˆ˜**: `(state) -> Literal["continue", "aggregate", "error"]`
- **ë°˜í™˜ê°’ì— ë”°ë¼ ë‹¤ë¥¸ ë…¸ë“œë¡œ ë¶„ê¸°**

### 2.4 ê·¸ë˜í”„ ì»´íŒŒì¼
```python
graph = builder.compile(
    checkpointer=AsyncSqliteSaver,  # ìƒíƒœ ì €ì¥ì†Œ
    durability="async"               # ì €ì¥ ëª¨ë“œ
)
```

---

## 3. State ê´€ë¦¬ ë©”ì»¤ë‹ˆì¦˜

### 3.1 AgentState êµ¬ì¡° (schemas/state.py)

```python
class AgentState(TypedDict):
    # ë©”ì‹œì§€ ê´€ë¦¬ (íŠ¹ìˆ˜ Annotated íƒ€ì…)
    messages: Annotated[List[AnyMessage], add_messages]

    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ
    current_agent: str
    agent_sequence: List[str]
    workflow_status: Literal["initializing", "analyzing", "executing",
                           "interrupted", "completed", "failed"]

    # ì§ˆì˜ ë¶„ì„
    user_query: str
    query_analysis: Dict[str, Any]
    execution_plan: List[Dict[str, Any]]

    # ì—ì´ì „íŠ¸ ê²°ê³¼ (ëª¨ë‘ Optional)
    analysis_results: Optional[Dict[str, Any]]
    search_results: Optional[Dict[str, Any]]
    documents: List[Dict[str, Any]]
    customer_insights: Optional[Dict[str, Any]]

    # ê¸°íƒ€
    errors: List[Dict[str, Any]]
    interrupt_data: Optional[Dict[str, Any]]
    metadata: Dict[str, Any]
    final_response: Optional[str]
```

### 3.2 State ì—…ë°ì´íŠ¸ ë©”ì»¤ë‹ˆì¦˜

**ë…¸ë“œ í•¨ìˆ˜ ë°˜í™˜ê°’ì´ Stateë¥¼ ì—…ë°ì´íŠ¸:**
```python
def analyze_query(state: AgentState, runtime: Runtime) -> Dict:
    return {
        "query_analysis": {...},      # ë®ì–´ì“°ê¸°
        "workflow_status": "analyzing",  # ë®ì–´ì“°ê¸°
        "messages": [AIMessage(...)]     # add_messagesë¡œ ì¶”ê°€
    }
```

**íŠ¹ìˆ˜ Annotated íƒ€ì… ë™ì‘:**
```python
messages: Annotated[List[AnyMessage], add_messages]
# add_messages ë¦¬ë“€ì„œê°€ ìƒˆ ë©”ì‹œì§€ë¥¼ ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
# ë‹¤ë¥¸ í•„ë“œëŠ” ë‹¨ìˆœ ë®ì–´ì“°ê¸°
```

---

## 4. ì½”ë“œ ì‹¤í–‰ íë¦„ (Line by Line)

### 4.1 ìš”ì²­ ì§„ì… (main.py)

```python
# LINE 147-186: POST /chat ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    # LINE 152: ì„¸ì…˜ ID ìƒì„± ë˜ëŠ” ì¬ì‚¬ìš©
    session_id = request.session_id or str(uuid.uuid4())

    # LINE 155-159: AgentContext ìƒì„± (ë¶ˆë³€ ì„¤ì •)
    context = AgentContext(
        user_id=request.user_id,        # í•„ìˆ˜
        company_id=request.company_id,  # í•„ìˆ˜
        session_id=session_id           # í•„ìˆ˜
    )
    # ê¸°ë³¸ê°’ ìë™ ì„¤ì •:
    # - model_provider: "openai"
    # - model_name: "gpt-4o"
    # - interrupt_mode: "critical"
    # - language: "ko"
    # - parallel_execution: True

    # LINE 162-165: ì»¨í…ìŠ¤íŠ¸ ì˜¤ë²„ë¼ì´ë“œ (ì„ íƒì )
    if request.context_override:
        for key, value in request.context_override.items():
            if hasattr(context, key):
                setattr(context, key, value)

    # LINE 168: ì´ˆê¸° State ìƒì„±
    initial_state = create_initial_state(request.query)
    # ë°˜í™˜ê°’:
    # {
    #     "messages": [],
    #     "current_agent": "supervisor",
    #     "agent_sequence": [],
    #     "workflow_status": "initializing",
    #     "user_query": request.query,
    #     "query_analysis": {},
    #     "execution_plan": [],
    #     "analysis_results": None,
    #     "search_results": None,
    #     "documents": [],
    #     "customer_insights": None,
    #     "errors": [],
    #     "interrupt_data": None,
    #     "metadata": {
    #         "start_time": "2024-XX-XX...",
    #         "version": "0.0.1"
    #     },
    #     "final_response": None
    # }

    # LINE 171: ì²´í¬í¬ì¸í„° ì„¤ì • ìƒì„±
    config = checkpointer_manager.get_config(session_id)
    # ë°˜í™˜ê°’:
    # {
    #     "configurable": {
    #         "thread_id": session_id,
    #         "checkpoint_ns": "",
    #         "checkpoint_id": None
    #     }
    # }

    # LINE 172-176: ê·¸ë˜í”„ ì‹¤í–‰ (ë¹„ë™ê¸°)
    result = await app.state.graph.ainvoke(
        initial_state,    # ì´ˆê¸° ìƒíƒœ
        context=context,  # Runtime ì»¨í…ìŠ¤íŠ¸
        config=config     # ì²´í¬í¬ì¸í„° ì„¤ì •
    )
```

### 4.2 ê·¸ë˜í”„ ìƒì„± (supervisor.py)

```python
# LINE 34-68: ê·¸ë˜í”„ êµ¬ì„±
def create_graph(self) -> StateGraph:
    # LINE 36-39: StateGraph ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    builder = StateGraph(
        state_schema=AgentState,      # TypedDict ìŠ¤í‚¤ë§ˆ
        context_schema=AgentContext    # dataclass ìŠ¤í‚¤ë§ˆ
    )

    # LINE 42-46: ë…¸ë“œ ì¶”ê°€ (í•¨ìˆ˜ ë ˆí¼ëŸ°ìŠ¤ ì „ë‹¬)
    builder.add_node("analyze_query", self.query_processor.analyze_query)
    builder.add_node("create_plan", self.query_processor.create_plan)
    builder.add_node("route_agents", self.agent_executor.route_agents)
    builder.add_node("aggregate_results", self.response_generator.aggregate_results)
    builder.add_node("generate_response", self.response_generator.generate_response)

    # LINE 49-51: ìˆœì°¨ ì—£ì§€ ì—°ê²°
    builder.add_edge(START, "analyze_query")          # ì‹œì‘ â†’ ë¶„ì„
    builder.add_edge("analyze_query", "create_plan")  # ë¶„ì„ â†’ ê³„íš
    builder.add_edge("create_plan", "route_agents")   # ê³„íš â†’ ë¼ìš°íŒ…

    # LINE 54-62: ì¡°ê±´ë¶€ ì—£ì§€ (route_agents ì´í›„)
    builder.add_conditional_edges(
        "route_agents",
        self.agent_executor.check_completion,  # ì¡°ê±´ í‰ê°€ í•¨ìˆ˜
        {
            "continue": "route_agents",      # ê³„ì† ì‹¤í–‰
            "aggregate": "aggregate_results", # ê²°ê³¼ ì·¨í•©
            "error": "generate_response"      # ì—ëŸ¬ ì²˜ë¦¬
        }
    )

    # LINE 64-65: ë§ˆì§€ë§‰ ì—£ì§€
    builder.add_edge("aggregate_results", "generate_response")
    builder.add_edge("generate_response", END)
```

### 4.3 Node 1: analyze_query (query_processor.py)

```python
# LINE 25-62: ì§ˆì˜ ë¶„ì„ ë…¸ë“œ
def analyze_query(
    self,
    state: AgentState,              # í˜„ì¬ ìƒíƒœ
    runtime: Runtime[AgentContext]  # ëŸ°íƒ€ì„ ì»¨í…ìŠ¤íŠ¸
) -> Dict[str, Any]:
    # LINE 31: ë¡œê¹…
    logger.info(f"Analyzing query for user: {runtime.context.user_id}")

    # LINE 33: LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ğŸ”´
    llm = self.utils.get_llm(runtime.context)
    # utils.py LINE 16-24:
    # if context.model_provider == "openai":
    #     return ChatOpenAI(
    #         model="gpt-4o",
    #         api_key=os.getenv("OPENAI_API_KEY"),
    #         temperature=0.7
    #     )

    # LINE 35-42: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    system_prompt = """ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ ì§ì›ì„ ìœ„í•œ ì±—ë´‡ì˜ ì§ˆì˜ ë¶„ì„ê¸°ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ íŒŒì•…í•˜ì„¸ìš”:
    1. ì‚¬ìš©ì ì˜ë„ (ë¶„ì„, ê²€ìƒ‰, ë¬¸ì„œìƒì„±, ê³ ê°ë¶„ì„ ë“±)
    2. í•„ìš”í•œ ì—ì´ì „íŠ¸ ëª©ë¡
    3. ì£¼ìš” ì—”í‹°í‹° (ê±°ë˜ì²˜ëª…, ì œí’ˆëª…, ê¸°ê°„ ë“±)
    4. ì§ˆì˜ ë³µì¡ë„ (0-1)

    ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”."""

    # LINE 44-47: ë©”ì‹œì§€ êµ¬ì„±
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=state["user_query"])  # "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„"
    ]

    # LINE 49: LLM í˜¸ì¶œ ğŸ”´
    response = llm.invoke(messages)
    # ì˜ˆìƒ ì‘ë‹µ:
    # {
    #   "intent": "analysis",
    #   "required_agents": ["analysis"],
    #   "entities": [
    #     {"type": "period", "value": "ì§€ë‚œ ë¶„ê¸°"}
    #   ],
    #   "complexity": 0.6,
    #   "keywords": ["ë§¤ì¶œ", "ë¶„ì„", "ë¶„ê¸°"]
    # }

    # LINE 51-54: JSON íŒŒì‹± (ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’)
    try:
        analysis = json.loads(response.content)
    except json.JSONDecodeError:
        analysis = self._get_default_analysis()
        # LINE 128-136:
        # return {
        #     "intent": "search",
        #     "required_agents": ["search"],
        #     "entities": [],
        #     "complexity": 0.5,
        #     "keywords": []
        # }

    # LINE 56-62: State ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "query_analysis": analysis,           # ë¶„ì„ ê²°ê³¼ ì €ì¥
        "workflow_status": "analyzing",       # ìƒíƒœ ë³€ê²½
        "messages": [                         # ë©”ì‹œì§€ ì¶”ê°€
            AIMessage(content=f"ì§ˆì˜ ë¶„ì„ ì™„ë£Œ: {analysis.get('intent', 'unknown')}")
        ]
    }
```

### 4.4 Node 2: create_plan (query_processor.py)

```python
# LINE 64-95: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½
def create_plan(
    self,
    state: AgentState,
    runtime: Runtime[AgentContext]
) -> Dict[str, Any]:
    # LINE 70: ë¡œê¹…
    logger.info("Creating execution plan")

    # LINE 72-73: ì´ì „ ë…¸ë“œ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    analysis = state.get("query_analysis", {})
    required_agents = analysis.get("required_agents", ["search"])
    # ì˜ˆ: ["analysis"] ë˜ëŠ” ["search", "document"]

    # LINE 76: ì‹¤í–‰ ê³„íš ìƒì„± (LLM ì—†ì´)
    plan = self._build_execution_plan(required_agents)

    # LINE 97-109: _build_execution_plan ìƒì„¸
    def _build_execution_plan(self, required_agents: List[str]) -> List[Dict]:
        plan = []
        for idx, agent in enumerate(required_agents):
            plan.append({
                "step_id": f"step_{idx+1}",
                "agent_name": agent,  # "analysis"
                "action": self.utils.get_agent_action(agent),
                # utils.py LINE 27-35:
                # {
                #   "analysis": "ë°ì´í„° ë¶„ì„ ë° í†µê³„ ìƒì„±",
                #   "search": "ì •ë³´ ê²€ìƒ‰ ë° ìˆ˜ì§‘",
                #   "document": "ë¬¸ì„œ ìë™ ìƒì„±",
                #   "customer": "ê³ ê° ë°ì´í„° ë¶„ì„"
                # }
                "dependencies": [] if idx == 0 else [f"step_{idx}"],
                "parallel": self.utils.can_run_parallel(agent, required_agents),
                # utils.py LINE 38-42:
                # parallel_compatible = ["search", "customer"]
                # return agent in parallel_compatible
                "estimated_time": self.utils.estimate_time(agent)
                # utils.py LINE 45-53:
                # times = {
                #   "analysis": 10,
                #   "search": 5,
                #   "document": 15,
                #   "customer": 8
                # }
            })
        return plan

    # LINE 79-87: ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬ (Human-in-the-loop)
    if runtime.context.interrupt_mode != "none":
        plan = self._handle_interrupts(plan, runtime.context)

    # LINE 111-126: _handle_interrupts ìƒì„¸
    def _handle_interrupts(self, plan: List[Dict], context: AgentContext):
        for step in plan:
            if self.utils.requires_approval(step["action"], context):
                # utils.py LINE 56-65:
                # if context.interrupt_mode == "all": return True
                # if context.interrupt_mode == "critical":
                #     approval_actions = ["sql_execution",
                #                        "document_generation",
                #                        "external_api_call"]
                #     return any(a in action.lower() for a in approval_actions)

                # LINE 119-123: interrupt í•¨ìˆ˜ (LangGraph API)
                approval = interrupt(
                    f"ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?\n"
                    f"ì—ì´ì „íŠ¸: {step['agent_name']}\n"
                    f"ì‘ì—…: {step['action']}"
                )
                if not approval:
                    return None

    # LINE 89-95: State ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "execution_plan": plan,
        "workflow_status": "executing",
        "messages": [
            AIMessage(content=f"ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(plan)}ê°œ ë‹¨ê³„")
        ]
    }
```

### 4.5 Node 3: route_agents (agent_executor.py)

```python
# LINE 20-53: ì—ì´ì „íŠ¸ ë¼ìš°íŒ…
def route_agents(
    self,
    state: AgentState,
    runtime: Runtime[AgentContext]
) -> Dict[str, Any]:
    # LINE 26: ë¡œê¹…
    logger.info("Routing to agents")

    # LINE 28-29: ê³„íšì—ì„œ ë‹¤ìŒ ë‹¨ê³„ ì°¾ê¸°
    plan = state.get("execution_plan", [])
    current_step = self._get_next_step(plan, state)

    # LINE 72-84: _get_next_step ìƒì„¸
    def _get_next_step(self, plan: List[Dict], state: AgentState):
        executed = state.get("agent_sequence", [])  # ì´ë¯¸ ì‹¤í–‰ëœ ì—ì´ì „íŠ¸
        for step in plan:
            if step["agent_name"] not in executed:
                deps = step.get("dependencies", [])
                # ì˜ì¡´ì„±ì´ ëª¨ë‘ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
                if all(d in executed for d in deps):
                    return step
        return None

    # LINE 31-33: ì™„ë£Œ ì²´í¬
    if not current_step:
        return {"workflow_status": "completed"}

    # LINE 35: í˜„ì¬ ì—ì´ì „íŠ¸ ì´ë¦„
    agent_name = current_step["agent_name"]  # ì˜ˆ: "analysis"

    # LINE 38-40: ë³‘ë ¬ ì‹¤í–‰ ì²˜ë¦¬
    parallel_agents = []
    if runtime.context.parallel_execution and current_step.get("parallel"):
        parallel_agents = self._get_parallel_agents(plan, current_step, state)

    # LINE 86-101: _get_parallel_agents ìƒì„¸
    def _get_parallel_agents(self, plan, current_step, state):
        parallel = []
        executed = state.get("agent_sequence", [])
        for step in plan:
            if (step != current_step and
                step.get("parallel") and
                step["agent_name"] not in executed):
                parallel.append(step)
        return parallel

    # LINE 43: Send ë©”ì»¤ë‹ˆì¦˜ ìƒì„± âš ï¸ ë¬¸ì œ: íƒ€ê²Ÿ ë…¸ë“œ ì—†ìŒ
    sends = self._create_sends(agent_name, parallel_agents, state, runtime.context)

    # LINE 103-126: _create_sends ìƒì„¸
    def _create_sends(self, agent_name, parallel_agents, state, context):
        sends = []
        if parallel_agents:
            for agent in parallel_agents:
                sends.append(Send(f"{agent['agent_name']}_agent", {
                    "state": state,
                    "context": context
                }))
        else:
            sends.append(Send(f"{agent_name}_agent", {  # "analysis_agent"
                "state": state,
                "context": context
            }))
        return sends
    # âš ï¸ SendëŠ” ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë…¸ë“œë¥¼ ê°€ë¦¬í‚´!

    # LINE 46: ì‹¤í–‰ëœ ì—ì´ì „íŠ¸ ëª©ë¡ ì—…ë°ì´íŠ¸
    executed_agents = [agent_name] + [a["agent_name"] for a in parallel_agents]

    # LINE 47-53: State ì—…ë°ì´íŠ¸
    return {
        "current_agent": agent_name,
        "agent_sequence": state.get("agent_sequence", []) + executed_agents,
        "messages": [
            AIMessage(content=f"ì‹¤í–‰ ì¤‘: {', '.join(executed_agents)}")
        ]
    }
```

### 4.6 ì¡°ê±´ë¶€ ë¼ìš°íŒ… í‰ê°€ (agent_executor.py)

```python
# LINE 55-70: ì™„ë£Œ ìƒíƒœ í™•ì¸ (ì¡°ê±´ë¶€ ì—£ì§€ìš©)
def check_completion(
    self,
    state: AgentState
) -> Literal["continue", "aggregate", "error"]:
    # LINE 60-61: ì—ëŸ¬ ì²´í¬
    if state.get("errors"):
        return "error"  # â†’ generate_responseë¡œ ì§í–‰

    # LINE 63-64: ì‹¤í–‰ ê³„íš ê°€ì ¸ì˜¤ê¸°
    plan = state.get("execution_plan", [])
    executed = state.get("agent_sequence", [])

    # LINE 66-68: ëª¨ë“  ì—ì´ì „íŠ¸ ì‹¤í–‰ ì™„ë£Œ í™•ì¸
    planned_agents = [step["agent_name"] for step in plan]
    if all(agent in executed for agent in planned_agents):
        return "aggregate"  # â†’ aggregate_resultsë¡œ

    # LINE 70: ê³„ì† ì‹¤í–‰
    return "continue"  # â†’ route_agents ë°˜ë³µ
```

### 4.7 Node 4: aggregate_results (response_generator.py)

```python
# LINE 24-45: ê²°ê³¼ ì·¨í•©
def aggregate_results(
    self,
    state: AgentState,
    runtime: Runtime[AgentContext]
) -> Dict[str, Any]:
    # LINE 30: ë¡œê¹…
    logger.info("Aggregating results")

    # LINE 33: ê° ì—ì´ì „íŠ¸ ê²°ê³¼ ìˆ˜ì§‘
    results = self._collect_results(state)

    # LINE 78-85: _collect_results ìƒì„¸
    def _collect_results(self, state: AgentState) -> Dict:
        return {
            "analysis": state.get("analysis_results"),    # None (ë¯¸êµ¬í˜„)
            "search": state.get("search_results"),        # None (ë¯¸êµ¬í˜„)
            "documents": state.get("documents"),          # []
            "customer": state.get("customer_insights")    # None (ë¯¸êµ¬í˜„)
        }

    # LINE 36: None ê°’ ì œê±°
    results = {k: v for k, v in results.items() if v is not None}
    # í˜„ì¬ ëª¨ë‘ Noneì´ë¯€ë¡œ results = {}

    # LINE 38-45: ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    return {
        "metadata": {
            **state.get("metadata", {}),  # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ìœ ì§€
            "aggregated_at": datetime.now().isoformat(),
            "total_agents": len(state.get("agent_sequence", [])),
            "results_count": len(results)  # 0
        }
    }
```

### 4.8 Node 5: generate_response (response_generator.py)

```python
# LINE 47-76: ìµœì¢… ì‘ë‹µ ìƒì„±
def generate_response(
    self,
    state: AgentState,
    runtime: Runtime[AgentContext]
) -> Dict[str, Any]:
    # LINE 53: ë¡œê¹…
    logger.info("Generating final response")

    # LINE 55: LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ğŸ”´
    llm = self.utils.get_llm(runtime.context)

    # LINE 58: ê²°ê³¼ ìš”ì•½
    results_summary = self._summarize_results(state)

    # LINE 87-104: _summarize_results ìƒì„¸
    def _summarize_results(self, state: AgentState) -> str:
        summary = []

        if state.get("analysis_results"):
            summary.append(f"ë¶„ì„ ê²°ê³¼: {state['analysis_results'].get('summary', 'N/A')}")

        if state.get("search_results"):
            count = len(state['search_results'].get('ranked_results', []))
            summary.append(f"ê²€ìƒ‰ ê²°ê³¼: {count}ê±´")

        if state.get("documents"):
            summary.append(f"ìƒì„±ëœ ë¬¸ì„œ: {len(state['documents'])}ê°œ")

        if state.get("customer_insights"):
            summary.append(f"ê³ ê° ì¸ì‚¬ì´íŠ¸: í¬í•¨")

        return "\n".join(summary) if summary else "ê²°ê³¼ ì—†ìŒ"
    # í˜„ì¬ ë°˜í™˜ê°’: "ê²°ê³¼ ì—†ìŒ"

    # LINE 61-65: LLM ì‘ë‹µ ìƒì„±
    response = self._create_response(
        llm,
        state["user_query"],      # "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„"
        results_summary,          # "ê²°ê³¼ ì—†ìŒ"
        runtime.context.language  # "ko"
    )

    # LINE 106-129: _create_response ìƒì„¸
    def _create_response(self, llm, user_query, results_summary, language):
        # LINE 114-122: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = f"""ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ ì§ì›ì„ ìœ„í•œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ {'í•œêµ­ì–´ë¡œ' if language == 'ko' else 'ì˜ì–´ë¡œ'}
        ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.

        ì‚¬ìš©ì ì§ˆë¬¸: {user_query}

        ë¶„ì„ ê²°ê³¼:
        {results_summary}
        """

        # LINE 124-127: ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content="ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.")
        ]

        # LINE 129: LLM í˜¸ì¶œ ğŸ”´
        return llm.invoke(messages)

    # LINE 67-76: State ì—…ë°ì´íŠ¸ (ìµœì¢…)
    return {
        "final_response": response.content,  # LLM ìƒì„± ì‘ë‹µ
        "workflow_status": "completed",
        "messages": [AIMessage(content=response.content)],
        "metadata": {
            **state.get("metadata", {}),
            "completed_at": datetime.now().isoformat()
        }
    }
```

---

## 5. LLM í˜¸ì¶œ ë¶„ì„

### 5.1 LLM í˜¸ì¶œ ì§€ì  (ì´ 2ê³³)

#### í˜¸ì¶œ 1: analyze_query (query_processor.py:49)
```python
# ëª©ì : ì‚¬ìš©ì ì§ˆì˜ ë¶„ì„
response = llm.invoke(messages)

# ì…ë ¥:
SystemMessage: "ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ ì§ì›ì„ ìœ„í•œ ì±—ë´‡ì˜ ì§ˆì˜ ë¶„ì„ê¸°ì…ë‹ˆë‹¤..."
HumanMessage: "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„"

# ì¶œë ¥ (JSON):
{
  "intent": "analysis",
  "required_agents": ["analysis"],
  "entities": [{"type": "period", "value": "ì§€ë‚œ ë¶„ê¸°"}],
  "complexity": 0.6,
  "keywords": ["ë§¤ì¶œ", "ë¶„ì„"]
}
```

#### í˜¸ì¶œ 2: generate_response (response_generator.py:129)
```python
# ëª©ì : ìµœì¢… ì‘ë‹µ ìƒì„±
response = llm.invoke(messages)

# ì…ë ¥:
SystemMessage: "ë‹¹ì‹ ì€ ì œì•½íšŒì‚¬ ì§ì›ì„ ìœ„í•œ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤..."
HumanMessage: "ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."

# ì¶œë ¥ (í…ìŠ¤íŠ¸):
"ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.
í˜„ì¬ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ëŠ” ìƒí™©ì…ë‹ˆë‹¤..."
```

### 5.2 LLM ì„¤ì • (utils.py:16-24)
```python
def get_llm(context: AgentContext):
    if context.model_provider == "openai":
        return ChatOpenAI(
            model=context.model_name,     # "gpt-4o"
            api_key=context.api_key,       # í™˜ê²½ë³€ìˆ˜
            temperature=0.7                # ê³ ì •ê°’
        )
```

---

## 6. í•¨ìˆ˜ë³„ ì…ì¶œë ¥ ëª…ì„¸

### 6.1 analyze_query
```python
ì…ë ¥:
  state: {
    "user_query": "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„",
    "workflow_status": "initializing",
    ...
  }
  runtime.context: AgentContext(user_id="user123", ...)

ì¶œë ¥:
  {
    "query_analysis": {
      "intent": "analysis",
      "required_agents": ["analysis"],
      ...
    },
    "workflow_status": "analyzing",
    "messages": [AIMessage(...)]
  }
```

### 6.2 create_plan
```python
ì…ë ¥:
  state: {
    "query_analysis": {"required_agents": ["analysis"]},
    ...
  }

ì¶œë ¥:
  {
    "execution_plan": [
      {
        "step_id": "step_1",
        "agent_name": "analysis",
        "action": "ë°ì´í„° ë¶„ì„ ë° í†µê³„ ìƒì„±",
        "dependencies": [],
        "parallel": false,
        "estimated_time": 10
      }
    ],
    "workflow_status": "executing"
  }
```

### 6.3 route_agents
```python
ì…ë ¥:
  state: {
    "execution_plan": [...],
    "agent_sequence": [],
    ...
  }

ì¶œë ¥:
  {
    "current_agent": "analysis",
    "agent_sequence": ["analysis"],
    "messages": [AIMessage("ì‹¤í–‰ ì¤‘: analysis")]
  }
```

### 6.4 check_completion
```python
ì…ë ¥:
  state: {
    "execution_plan": [{"agent_name": "analysis"}],
    "agent_sequence": ["analysis"],
    ...
  }

ì¶œë ¥: "aggregate"  # Literal íƒ€ì…
```

### 6.5 aggregate_results
```python
ì…ë ¥:
  state: {
    "analysis_results": None,
    "search_results": None,
    ...
  }

ì¶œë ¥:
  {
    "metadata": {
      "aggregated_at": "2024-...",
      "total_agents": 1,
      "results_count": 0
    }
  }
```

### 6.6 generate_response
```python
ì…ë ¥:
  state: {
    "user_query": "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„",
    "analysis_results": None,
    ...
  }

ì¶œë ¥:
  {
    "final_response": "ë§¤ì¶œ ë¶„ì„ ê²°ê³¼...",
    "workflow_status": "completed",
    "messages": [AIMessage(...)],
    "metadata": {"completed_at": "2024-..."}
  }
```

---

## 7. ë¯¸ì‚¬ìš© ì½”ë“œ ë¶„ì„

### 7.1 Send ë©”ì»¤ë‹ˆì¦˜ (agent_executor.py)
```python
# LINE 43, 103-126
sends = self._create_sends(...)
Send(f"{agent_name}_agent", {...})
```
**ë¬¸ì œ**: "analysis_agent", "search_agent" ë“± ë…¸ë“œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ

### 7.2 ë³‘ë ¬ ì‹¤í–‰ ë¡œì§ (agent_executor.py)
```python
# LINE 38-40, 86-101
parallel_agents = self._get_parallel_agents(...)
```
**ë¬¸ì œ**: Sendê°€ ì‘ë™í•˜ì§€ ì•Šì•„ ë³‘ë ¬ ì‹¤í–‰ ë¶ˆê°€ëŠ¥

### 7.3 ì¸í„°ëŸ½íŠ¸ ë°ì´í„° (state.py)
```python
# LINE 132-141
class InterruptData(BaseModel):
    interrupt_id: str
    reason: str
    ...
```
**ë¬¸ì œ**: ì‹¤ì œë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ

### 7.4 ì—ëŸ¬ ì²˜ë¦¬ ê²½ë¡œ
```python
# check_completionì—ì„œ "error" ë°˜í™˜
if state.get("errors"):
    return "error"
```
**ë¬¸ì œ**: errors í•„ë“œë¥¼ ì„¤ì •í•˜ëŠ” ì½”ë“œ ì—†ìŒ

### 7.5 WebSocket ì¸í„°ëŸ½íŠ¸ (main.py)
```python
# LINE 282-309
async def process_interrupt_response(session_id: str, data: dict):
    command = Command(resume=data.get("value"))
```
**ë¬¸ì œ**: ì¸í„°ëŸ½íŠ¸ ë°œìƒ ì½”ë“œ ì—†ìŒ

---

## 8. ê°œì„  í•„ìš” ì‚¬í•­

### 8.1 ì¦‰ì‹œ ê°œì„  ê°€ëŠ¥
1. Send ë©”ì»¤ë‹ˆì¦˜ ì œê±° ë˜ëŠ” ìˆ˜ì •
2. ë¯¸ì‚¬ìš© ìŠ¤í‚¤ë§ˆ ì •ë¦¬
3. ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§ êµ¬í˜„

### 8.2 êµ¬ì¡°ì  ê°œì„ 
1. ì‹¤ì œ ì—ì´ì „íŠ¸ ë…¸ë“œ êµ¬í˜„
2. ë„êµ¬(Tools) ì‹œìŠ¤í…œ êµ¬ì¶•
3. ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™

### 8.3 ìµœì í™”
1. LLM í˜¸ì¶œ ìºì‹±
2. ë³‘ë ¬ ì‹¤í–‰ ì‹¤ì œ êµ¬í˜„
3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ê°œì„ 

---

## 9. ë°ì´í„° íë¦„ ì˜ˆì‹œ

### ì…ë ¥: "ì§€ë‚œ ë¶„ê¸° ë§¤ì¶œ ë¶„ì„"

```
1. initial_state ìƒì„±
   â†“
2. analyze_query: LLMì´ intent="analysis" íŒë‹¨
   â†“
3. create_plan: [{agent_name: "analysis", ...}] ìƒì„±
   â†“
4. route_agents: Send("analysis_agent") ì‹œë„ (ì‹¤íŒ¨)
   â†“
5. check_completion: "aggregate" ë°˜í™˜
   â†“
6. aggregate_results: ë¹ˆ ê²°ê³¼ ì·¨í•©
   â†“
7. generate_response: LLMì´ "ê²°ê³¼ ì—†ìŒ" ë³´ê³  ì¼ë°˜ ë‹µë³€ ìƒì„±
   â†“
8. ìµœì¢… ì‘ë‹µ: "í˜„ì¬ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤..."
```

---

## 10. í•µì‹¬ ë¬¸ì œì  ìš”ì•½

1. **ì—ì´ì „íŠ¸ ë¯¸êµ¬í˜„**: 4ê°œ ì—ì´ì „íŠ¸ ë…¸ë“œ ì—†ìŒ
2. **Send ë©”ì»¤ë‹ˆì¦˜ ë¬´ìš©**: íƒ€ê²Ÿ ë…¸ë“œ ë¶€ì¬
3. **ë„êµ¬ ì‹œìŠ¤í…œ ë¶€ì¬**: DB ì—°ë™, API í˜¸ì¶œ ë¶ˆê°€
4. **LLM ì˜ì¡´ë„**: ì‹¤ì œ ë°ì´í„° ì—†ì´ LLMë§Œìœ¼ë¡œ ì‘ë‹µ

ì´ ì‹œìŠ¤í…œì€ **í”„ë ˆì„ì›Œí¬ëŠ” ì™„ì„±**ë˜ì—ˆìœ¼ë‚˜ **ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì´ ì—†ëŠ”** ìƒíƒœì…ë‹ˆë‹¤.